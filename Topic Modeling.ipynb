{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Find the right combination of data-to-vector methods and topic models to get models that best represent the data.\n",
    "\n",
    "Text data to vector methods:\n",
    "* Count Vectorizer: Counts the number of times a word appears in a document.\n",
    "* Tfidf Vectorizer: Considers the overall document weightage.\n",
    "\n",
    "Topic models:\n",
    "* Non-negative Matrix Factorization (NMF)\n",
    "* Latent Dirichlet Allocation (LDA)\n",
    "* CorEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-18T23:11:09.557148Z",
     "start_time": "2021-02-18T23:11:09.553394Z"
    }
   },
   "source": [
    "# Import Data and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:09:04.745361Z",
     "start_time": "2021-02-19T00:09:02.686725Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import make_multilabel_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:09:05.337475Z",
     "start_time": "2021-02-19T00:09:04.790597Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:09:06.024147Z",
     "start_time": "2021-02-19T00:09:05.986811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>wid</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital</th>\n",
       "      <th>parenthood</th>\n",
       "      <th>reflection_period</th>\n",
       "      <th>...</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>proto_agent</th>\n",
       "      <th>passive_agent</th>\n",
       "      <th>root_verb</th>\n",
       "      <th>direct_object</th>\n",
       "      <th>parenthood_cat</th>\n",
       "      <th>gender_cat</th>\n",
       "      <th>marital_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "      <td>24h</td>\n",
       "      <td>...</td>\n",
       "      <td>['wife', 'celebrating', 'year', 'anniversary',...</td>\n",
       "      <td>[celebrating]</td>\n",
       "      <td>[wife, year, anniversary, today]</td>\n",
       "      <td>[wife]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[celebrating]</td>\n",
       "      <td>[anniversary]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "      <td>24h</td>\n",
       "      <td>...</td>\n",
       "      <td>['mother', 'called', 'blue', 'tell', 'proud']</td>\n",
       "      <td>[called, tell]</td>\n",
       "      <td>[mother, blue]</td>\n",
       "      <td>[mother, she]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[called]</td>\n",
       "      <td>[me]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "      <td>24h</td>\n",
       "      <td>...</td>\n",
       "      <td>['today', 'took', 'day', 'time', 'job', 'brunc...</td>\n",
       "      <td>[took, go, have]</td>\n",
       "      <td>[Today, day, part, time, job, brunch, date, wife]</td>\n",
       "      <td>[i]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[took]</td>\n",
       "      <td>[day, date]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "      <td>24h</td>\n",
       "      <td>...</td>\n",
       "      <td>['just', 'got', 'bonus', 'mturk', 'task']</td>\n",
       "      <td>[got]</td>\n",
       "      <td>[bonus, mturk, task]</td>\n",
       "      <td>[I]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[got]</td>\n",
       "      <td>[bonus]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>USA</td>\n",
       "      <td>m</td>\n",
       "      <td>married</td>\n",
       "      <td>y</td>\n",
       "      <td>24h</td>\n",
       "      <td>...</td>\n",
       "      <td>['wife', 'cooked', 'surprise', 'dinner', 'work']</td>\n",
       "      <td>[cooked, take, work]</td>\n",
       "      <td>[wife, surprise, dinner]</td>\n",
       "      <td>[wife]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cooked]</td>\n",
       "      <td>[dinner]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  wid  age country gender  marital  \\\n",
       "0           0             0               0    1   37     USA      m  married   \n",
       "1           1             1               1    1   37     USA      m  married   \n",
       "2           2             2               2    1   37     USA      m  married   \n",
       "3           3             3               3    1   37     USA      m  married   \n",
       "4           4             4               4    1   37     USA      m  married   \n",
       "\n",
       "  parenthood reflection_period  ...  \\\n",
       "0          y               24h  ...   \n",
       "1          y               24h  ...   \n",
       "2          y               24h  ...   \n",
       "3          y               24h  ...   \n",
       "4          y               24h  ...   \n",
       "\n",
       "                                        text_cleaned                 verbs  \\\n",
       "0  ['wife', 'celebrating', 'year', 'anniversary',...         [celebrating]   \n",
       "1      ['mother', 'called', 'blue', 'tell', 'proud']        [called, tell]   \n",
       "2  ['today', 'took', 'day', 'time', 'job', 'brunc...      [took, go, have]   \n",
       "3          ['just', 'got', 'bonus', 'mturk', 'task']                 [got]   \n",
       "4   ['wife', 'cooked', 'surprise', 'dinner', 'work']  [cooked, take, work]   \n",
       "\n",
       "                                               nouns    proto_agent  \\\n",
       "0                   [wife, year, anniversary, today]         [wife]   \n",
       "1                                     [mother, blue]  [mother, she]   \n",
       "2  [Today, day, part, time, job, brunch, date, wife]            [i]   \n",
       "3                               [bonus, mturk, task]            [I]   \n",
       "4                           [wife, surprise, dinner]         [wife]   \n",
       "\n",
       "  passive_agent      root_verb  direct_object parenthood_cat  gender_cat  \\\n",
       "0            []  [celebrating]  [anniversary]              1           1   \n",
       "1            []       [called]           [me]              1           1   \n",
       "2            []         [took]    [day, date]              1           1   \n",
       "3            []          [got]        [bonus]              1           1   \n",
       "4            []       [cooked]       [dinner]              1           1   \n",
       "\n",
       "   marital_cat  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T01:02:39.226239Z",
     "start_time": "2021-02-19T01:02:39.213907Z"
    }
   },
   "outputs": [],
   "source": [
    "def nmf(column, num_categories, vector_type, model_type):\n",
    "    # Vectorize the data\n",
    "    vectorizer = vector_type\n",
    "    doc_word = vectorizer.fit_transform(column)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = model_type(num_categories)\n",
    "    doc_topic = model.fit_transform(doc_word)\n",
    "    \n",
    "    # Make a list of the words for classifications\n",
    "    words = vectorizer.get_feature_names()\n",
    "    t = model.components_.argsort(axis=1)[:,-1:-7:-1]\n",
    "    topic_words = [[words[e] for e in l] for l in t]\n",
    "    \n",
    "    count = 0\n",
    "    for topic_list in topic_words:\n",
    "        print('Topic ', count, ': ', *topic_list)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:15:28.299481Z",
     "start_time": "2021-02-19T00:15:28.292228Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_stoppers = ['wa', 'able', 'day', 'nice', 'month', 'year', 'today', 'week',\n",
    "                 'yesterday', 'ha', 'moment', 'life', 'like', 'just', 'lot',\n",
    "                 'spend', 'spent', 'spending']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:15:38.450965Z",
     "start_time": "2021-02-19T00:15:31.722998Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  1 :  time family long home make work\n",
      "Topic  2 :  got work job home finally son\n",
      "Topic  3 :  friend old best birthday party school\n",
      "Topic  4 :  new bought car job game house\n",
      "Topic  5 :  went family movie dinner shopping night\n",
      " \n",
      "Topic  1 :  time family long make home night\n",
      "Topic  2 :  got job finally son night school\n",
      "Topic  3 :  friend old best birthday party school\n",
      "Topic  4 :  new bought car job house game\n",
      "Topic  5 :  went family movie dinner shopping night\n",
      "Topic  6 :  work home make came project getting\n",
      " \n",
      "Topic  1 :  time long family movement exam person\n",
      "Topic  2 :  got job finally promotion free sleep\n",
      "Topic  3 :  friend best old birthday party met\n",
      "Topic  4 :  new bought car job game phone\n",
      "Topic  5 :  went movie shopping temple dinner enjoyed\n",
      "Topic  6 :  work home project job received early\n",
      "Topic  7 :  family home make said came son\n"
     ]
    }
   ],
   "source": [
    "nmf(df.text_cleaned, 5, CountVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 6, CountVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 7, CountVectorizer(stop_words = extra_stoppers), NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:12:11.095684Z",
     "start_time": "2021-02-19T00:11:50.558028Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic  1 :  friend birthday best old party met\n",
      "Topic  2 :  got work job promotion raise home\n",
      "Topic  3 :  went movie shopping temple walk park\n",
      "Topic  4 :  new bought car job game purchased\n",
      "Topic  5 :  time dinner family long night wife\n",
      " \n",
      "Topic  1 :  friend birthday best old party met\n",
      "Topic  2 :  work home early project received finished\n",
      "Topic  3 :  went movie shopping temple walk park\n",
      "Topic  4 :  new bought car job game purchased\n",
      "Topic  5 :  time dinner family long night wife\n",
      "Topic  6 :  got job sleep promotion finally raise\n",
      " \n",
      "Topic  1 :  friend birthday best old party met\n",
      "Topic  2 :  work home early project received finished\n",
      "Topic  3 :  went movie shopping temple walk family\n",
      "Topic  4 :  new bought car job game purchased\n",
      "Topic  5 :  dinner family wife night ate favorite\n",
      "Topic  6 :  got job sleep promotion finally raise\n",
      "Topic  7 :  time long daughter spend son family\n",
      " \n",
      "Topic  1 :  friend old best met seen talked\n",
      "Topic  2 :  work home early project received finished\n",
      "Topic  3 :  went movie shopping temple walk family\n",
      "Topic  4 :  new bought car job game purchased\n",
      "Topic  5 :  dinner wife night ate family favorite\n",
      "Topic  6 :  got job sleep promotion finally raise\n",
      "Topic  7 :  time long spend spent dog daughter\n",
      "Topic  8 :  birthday party family celebrated daughter son\n",
      " \n",
      "Topic  1 :  friend old best met seen talked\n",
      "Topic  2 :  work home early project received finished\n",
      "Topic  3 :  went movie shopping temple walk family\n",
      "Topic  4 :  new bought car job purchased phone\n",
      "Topic  5 :  dinner wife night ate family delicious\n",
      "Topic  6 :  got job sleep promotion finally raise\n",
      "Topic  7 :  time long spend spent family dog\n",
      "Topic  8 :  birthday party family celebrated daughter son\n",
      "Topic  9 :  game video played won playing favorite\n",
      " \n",
      "Topic  1 :  friend old best met seen talked\n",
      "Topic  2 :  work home early project received finished\n",
      "Topic  3 :  went shopping temple walk park trip\n",
      "Topic  4 :  new bought car job purchased phone\n",
      "Topic  5 :  dinner wife night ate family delicious\n",
      "Topic  6 :  got job sleep promotion finally raise\n",
      "Topic  7 :  time long spend spent family home\n",
      "Topic  8 :  birthday party family celebrated daughter son\n",
      "Topic  9 :  game video played won playing play\n",
      "Topic  10 :  movie watched favorite watching watch tv\n",
      " \n",
      "Topic  1 :  friend best old met seen talked\n",
      "Topic  2 :  work project early received finished raise\n",
      "Topic  3 :  went shopping temple walk park trip\n",
      "Topic  4 :  new bought car job purchased phone\n",
      "Topic  5 :  dinner ate family night wife delicious\n",
      "Topic  6 :  got job promotion sleep finally raise\n",
      "Topic  7 :  time long spend spent family spending\n",
      "Topic  8 :  birthday party family celebrated gift surprise\n",
      "Topic  9 :  game video played won playing play\n",
      "Topic  10 :  movie watched favorite watching watch tv\n",
      "Topic  11 :  home dog came son daughter wife\n"
     ]
    }
   ],
   "source": [
    "nmf(df.text_cleaned, 5, TfidfVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 6, TfidfVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 7, TfidfVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 8, TfidfVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 9, TfidfVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 10, TfidfVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 11, TfidfVectorizer(stop_words = extra_stoppers), NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:17:07.290642Z",
     "start_time": "2021-02-19T00:16:55.714506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Topic  1 :  friend best old met seen talked\n",
      "Topic  2 :  work early project finished raise received\n",
      "Topic  3 :  went shopping temple walk park trip\n",
      "Topic  4 :  new bought car purchased phone house\n",
      "Topic  5 :  dinner ate night wife family delicious\n",
      "Topic  6 :  got sleep promotion finally free raise\n",
      "Topic  7 :  time long family seen quality havent\n",
      "Topic  8 :  birthday family party celebrated gift surprise\n",
      "Topic  9 :  home dog came son daughter took\n",
      "Topic  10 :  movie watched favorite watching watch tv\n",
      "Topic  11 :  game video played won playing play\n",
      "Topic  12 :  job interview received getting new offer\n",
      " \n",
      "Topic  1 :  friend best old met seen talked\n",
      "Topic  2 :  work early project finished raise received\n",
      "Topic  3 :  went shopping temple walk park trip\n",
      "Topic  4 :  new bought car purchased phone house\n",
      "Topic  5 :  dinner ate night delicious wife favorite\n",
      "Topic  6 :  got sleep promotion finally free raise\n",
      "Topic  7 :  time long family seen quality finally\n",
      "Topic  8 :  birthday family party celebrated gift surprise\n",
      "Topic  9 :  daughter son wife school morning old\n",
      "Topic  10 :  movie watched favorite watching watch tv\n",
      "Topic  11 :  game video played won playing play\n",
      "Topic  12 :  home dog came husband walk took\n",
      "Topic  13 :  job interview received getting new offer\n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "nmf(df.text_cleaned, 12, TfidfVectorizer(stop_words = extra_stoppers), NMF)\n",
    "\n",
    "print(' ')\n",
    "nmf(df.text_cleaned, 13, TfidfVectorizer(stop_words = extra_stoppers), NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:15:46.511788Z",
     "start_time": "2021-02-19T00:15:38.984562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Topic  1 :  friend best old met seen talked\n",
      "Topic  2 :  work project early finished raise received\n",
      "Topic  3 :  went shopping temple walk trip date\n",
      "Topic  4 :  new bought car purchased phone house\n",
      "Topic  5 :  dinner ate night wife delicious family\n",
      "Topic  6 :  got sleep promotion finally free raise\n",
      "Topic  7 :  time long family seen quality finally\n",
      "Topic  8 :  birthday family party celebrated gift surprise\n",
      "Topic  9 :  daughter son wife school morning old\n",
      "Topic  10 :  movie watched favorite watching watch tv\n",
      "Topic  11 :  game video played won playing play\n",
      "Topic  12 :  job interview received getting new offer\n",
      "Topic  13 :  home came husband visit house sister\n",
      "Topic  14 :  dog walk took park long outside\n"
     ]
    }
   ],
   "source": [
    "print(' ')\n",
    "nmf(df.text_cleaned, 14, TfidfVectorizer(stop_words = extra_stoppers), NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:52:23.706551Z",
     "start_time": "2021-02-19T00:52:23.700504Z"
    }
   },
   "outputs": [],
   "source": [
    "def lda(column, num_categories):\n",
    "    \n",
    "    # Vectorize the data\n",
    "    # LDA can only use raw term counts for LDA because it is a probabilistic \n",
    "    # graphical model\n",
    "    tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words=extra_stoppers)\n",
    "    tf = tf_vectorizer.fit_transform(column)\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    \n",
    "    # Instantiate the model\n",
    "    lda = LatentDirichletAllocation(n_components=num_categories, max_iter=5, \n",
    "                                    learning_method='online', learning_offset=50.,\n",
    "                                    random_state=0).fit(tf)\n",
    "    \n",
    "    # Print top words for each topic\n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        print(\"Topic %d:\" % (topic_idx), \" \".join([tf_feature_names[i] for i in topic.argsort()[:-6 - 1:-1]]))\n",
    "    \n",
    "    #no_top_words = 6\n",
    "    #display_topics(lda, tf_feature_names, no_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-19T00:53:49.439563Z",
     "start_time": "2021-02-19T00:52:57.959044Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: work got job finally new car\n",
      "Topic 1: wife having took lunch boyfriend got\n",
      "Topic 2: friend birthday went past movie enjoyed\n",
      "Topic 3: went old event started time child\n",
      "Topic 4: time dinner family night long food\n",
      "Topic 5: best won watched said son free\n",
      "Topic 6: came dog going favorite finished trip\n",
      "Topic 7: home received ago did sister got\n",
      "Topic 8: daughter morning school got time make\n",
      "Topic 9: new game getting love bought watching\n"
     ]
    }
   ],
   "source": [
    "lda(df.text_cleaned, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
